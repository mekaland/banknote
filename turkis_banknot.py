# -*- coding: utf-8 -*-
"""turkis-banknot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CFuMQZzW-VoWUV1MXtpkTDgpwUrvc1Or

## Türk lirası banknot tanıma
"""

import cv2 
import pandas as pd
import os
import matplotlib.pyplot as plt
import numpy as np

"""## Veri Setini Tanımla"""

labels =['5','10','20','50','100','200']
img_path = '/kaggle/input/turkish-lira-banknote-dataset/'

from PIL import Image
img = Image.open('/kaggle/input/turkish-lira-banknote-dataset/5/5_1_0001.png')
plt.imshow(img)

#DF için img ve label listesi
img_list=[]
label_list=[]
for label in labels:
    for img_file in os.listdir(img_path + label):
        img_list.append(img_path+label+'/'+img_file)
        label_list.append(label)

df = pd.DataFrame({'path':img_list,'label':label_list})
df.head()

df.sample(5) #rastgele alır

df.info()

"""## Etiketleri label encoding yapalım"""

d = {'5':0,'10':1,'20':2,'50':3,'100':4,'200':5}

df['encode_labels']=df['label'].map(d)
df

"""## etiket dağılımı"""

df['label'].value_counts().plot(kind='bar')

fig,ax=plt.subplots(4,4,figsize=(10,10))
df_sample=df.sample(16)
for i,axi in enumerate(ax.flat):
    axi.imshow(cv2.imread(str(df_sample['path'].iloc[i])))
    axi.set(xticks=[],yticks=[],xlabel=df_sample['label'].iloc[i])

"""## Resimleri Ön İşleme"""

X=[]
for img in df['path']:
    img = cv2.imread(img)
    img = cv2.resize(img,(30,30))
    img=img/255.0
    X.append(img)

"""X=np.array(X)"""

def img_preprocess(df):
    for img in df:
        img = cv2.imread(img)
        img = cv2.resize(img,(30,30))
        img=img/255.0
        X.append(img)
        X=np.array(X)
        return X

y=df['encode_labels']

"""## Veri setini böl"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

"""## Modeli oluştur"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Input
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam

# Modeli oluştur
model = Sequential()

# Input katmanı
model.add(Input(shape=(30, 30, 3))) #resmimizin boyutu 30 30 ve rgb 3

# 1. Convential bloğu
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.25))

# 2. Convential bloğu
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.25))

# 3. Convential bloğu
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.25))

# 4. Convential bloğu
model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.25))

# Tam bağlantılı katmanlar
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(6, activation='softmax'))

# Erken durdurma
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)

# Modeli derle
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Modelin özetini yazdır
model.summary()

"""## Modeli Eğit"""

history = model.fit(X_train, y_train,
                    validation_data=(X_test, y_test), #validation_split=0.2,
                    epochs=10,
                    callbacks=[early_stopping],
                    verbose=1)

model.save('model.h5')

"""## Modeli değerlendir"""

#val üzerinden tahminleri yap ve karılaştır
y_pred_proba=model.predict(X_test)

y_pred_proba

y_pred=np.argmax(y_pred_proba,axis=1)

df_cm=pd.DataFrame({'Gerçek Değerler':y_test,'Tahmin Edilen Değerler':y_pred})
df_cm

from sklearn.metrics import confusion_matrix,classification_report
print(classification_report(y_test,y_pred))
confusion_matrix(y_test,y_pred)

import seaborn as sns
sns.heatmap(confusion_matrix(y_test,y_pred),annot=True, fmt="d")
plt.show()

